{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-18T12:00:31.420535800Z",
     "start_time": "2023-10-18T12:00:30.923464500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sqlalchemy import create_engine,Text\n",
    "from ingestor import ParquetIngestor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T13:46:48.577536300Z",
     "start_time": "2023-10-18T13:46:48.489170300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<sqlalchemy.engine.base.Connection at 0x2ae03a3aa10>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating postgres database engine\n",
    "engine = create_engine('postgresql://data:data@localhost:5432/ny_taxis')\n",
    "engine_2 = create_engine('postgresql://data:data@localhost:5433/airflow')\n",
    "engine.connect()\n",
    "engine_2.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T13:49:19.163188900Z",
     "start_time": "2023-10-18T13:49:18.665696300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     LocationID        Borough                     Zone service_zone\n0             1            EWR           Newark Airport          EWR\n1             2         Queens              Jamaica Bay    Boro Zone\n2             3          Bronx  Allerton/Pelham Gardens    Boro Zone\n3             4      Manhattan            Alphabet City  Yellow Zone\n4             5  Staten Island            Arden Heights    Boro Zone\n..          ...            ...                      ...          ...\n260         261      Manhattan       World Trade Center  Yellow Zone\n261         262      Manhattan           Yorkville East  Yellow Zone\n262         263      Manhattan           Yorkville West  Yellow Zone\n263         264        Unknown                       NV          NaN\n264         265        Unknown                      NaN          NaN\n\n[265 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LocationID</th>\n      <th>Borough</th>\n      <th>Zone</th>\n      <th>service_zone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>EWR</td>\n      <td>Newark Airport</td>\n      <td>EWR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Queens</td>\n      <td>Jamaica Bay</td>\n      <td>Boro Zone</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Bronx</td>\n      <td>Allerton/Pelham Gardens</td>\n      <td>Boro Zone</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Manhattan</td>\n      <td>Alphabet City</td>\n      <td>Yellow Zone</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Staten Island</td>\n      <td>Arden Heights</td>\n      <td>Boro Zone</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>260</th>\n      <td>261</td>\n      <td>Manhattan</td>\n      <td>World Trade Center</td>\n      <td>Yellow Zone</td>\n    </tr>\n    <tr>\n      <th>261</th>\n      <td>262</td>\n      <td>Manhattan</td>\n      <td>Yorkville East</td>\n      <td>Yellow Zone</td>\n    </tr>\n    <tr>\n      <th>262</th>\n      <td>263</td>\n      <td>Manhattan</td>\n      <td>Yorkville West</td>\n      <td>Yellow Zone</td>\n    </tr>\n    <tr>\n      <th>263</th>\n      <td>264</td>\n      <td>Unknown</td>\n      <td>NV</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>264</th>\n      <td>265</td>\n      <td>Unknown</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>265 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing links to the taxi data\n",
    "yellow_taxi_link = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet'\n",
    "green_taxi_link = 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2022-01.parquet'\n",
    "for_hire_link = 'https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2022-01.parquet'\n",
    "taxi_lookup_link = 'https://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv'\n",
    "\n",
    "# Importing the taxi location codes into pandas\n",
    "lookup_df = pd.read_csv(taxi_lookup_link)\n",
    "lookup_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T13:54:47.999295100Z",
     "start_time": "2023-10-18T13:54:47.986801200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to get Parquet(data files)\n",
    "def get_parquet(link):\n",
    "    df = pd.read_parquet(link)\n",
    "    df.columns = df.columns.str.lower()\n",
    "    return df\n",
    "\n",
    "# Function to created table header\n",
    "def create_header(df,table_name, db_connection):\n",
    "    df.head(0).to_sql(table_name, con=db_connection, if_exists='replace')\n",
    "\n",
    "# Function to ingest data into the postgres database\n",
    "def ingest_chunk(df,table_name,chunk_size=100000):\n",
    "    df_len = len(df)\n",
    "    chunk_no = round(df_len/chunk_size)\n",
    "\n",
    "    for idx in range(0,len(df),chunk_size):\n",
    "        print('Starting data ingestion into the database')\n",
    "        print(f'Ingesting chunk {round((idx+chunk_size)/chunk_size)} of {chunk_no}')\n",
    "        start_time = time()\n",
    "\n",
    "        ingest_df = df[idx:idx+chunk_size]\n",
    "        ingest_df.to_sql(table_name,con=engine, if_exists='append')\n",
    "\n",
    "        end_time = time()\n",
    "        print(f'Data ingestion chunk {round((idx+chunk_size)/chunk_size)} of {chunk_no} ended')\n",
    "        print(f'Time taken: {end_time-start_time:.2f}')\n",
    "\n",
    "    return 'Ingestion completed'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data ingestion into the database\n",
      "Ingesting chunk 1 of 1\n",
      "Data ingestion chunk 1 of 1 ended\n",
      "Time taken: 7.51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ingestion completed'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ingesting Green Taxi\n",
    "green_taxi_df = get_parquet(green_taxi_link)\n",
    "green_ingestor = ParquetIngestor(engine,green_taxi_df)\n",
    "green_ingestor.create_header('green_taxi')\n",
    "green_ingestor.ingest_chunk('green_taxi')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " def run_ingestion(file, db_conn, table_name):\n",
    "    ingestor = ParquetIngestor(file, db_conn, table_name)\n",
    "    df = ingestor.create_dataframe()\n",
    "    ingestor.ingest_chunk(df)\n",
    "    ingestor.create_header(df)\n",
    "    ingestor.ingest_chunk(df)\n",
    "\n",
    "    print('Ingestion Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_ingestion(taxi_lookup_link,engine,'taxi_zone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_ingestion(for_hire_link,engine,'for_hire')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1143691"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.read_parquet(for_hire_link))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "query = \"\"\" SELECT * FROM yellow_taxi LIMIT 1000\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ObjectNotExecutableError",
     "evalue": "Not an executable object: Text(length=' SELECT * FROM yellow_taxi LIMIT 1000')",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[0;32m~/Documents/Data Projects/zoomcamp/pipeline/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1410\u001B[0m, in \u001B[0;36mConnection.execute\u001B[0;34m(self, statement, parameters, execution_options)\u001B[0m\n\u001B[1;32m   1409\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1410\u001B[0m     meth \u001B[38;5;241m=\u001B[39m \u001B[43mstatement\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execute_on_connection\u001B[49m\n\u001B[1;32m   1411\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'Text' object has no attribute '_execute_on_connection'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mObjectNotExecutableError\u001B[0m                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m conn \u001B[38;5;241m=\u001B[39m create_engine(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpostgresql://root:root@localhost:5432/ny_taxi\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_sql_query\u001B[49m\u001B[43m(\u001B[49m\u001B[43mText\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43mcon\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Data Projects/zoomcamp/pipeline/lib/python3.10/site-packages/pandas/io/sql.py:397\u001B[0m, in \u001B[0;36mread_sql_query\u001B[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype)\u001B[0m\n\u001B[1;32m    339\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    340\u001B[0m \u001B[38;5;124;03mRead SQL query into a DataFrame.\u001B[39;00m\n\u001B[1;32m    341\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    394\u001B[0m \u001B[38;5;124;03mparameter will be converted to UTC.\u001B[39;00m\n\u001B[1;32m    395\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    396\u001B[0m pandas_sql \u001B[38;5;241m=\u001B[39m pandasSQL_builder(con)\n\u001B[0;32m--> 397\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpandas_sql\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_query\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    398\u001B[0m \u001B[43m    \u001B[49m\u001B[43msql\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    399\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindex_col\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex_col\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    400\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    401\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcoerce_float\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcoerce_float\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    402\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparse_dates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparse_dates\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    403\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunksize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    404\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    405\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Data Projects/zoomcamp/pipeline/lib/python3.10/site-packages/pandas/io/sql.py:1560\u001B[0m, in \u001B[0;36mSQLDatabase.read_query\u001B[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype)\u001B[0m\n\u001B[1;32m   1512\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1513\u001B[0m \u001B[38;5;124;03mRead SQL query into a DataFrame.\u001B[39;00m\n\u001B[1;32m   1514\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1556\u001B[0m \n\u001B[1;32m   1557\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m args \u001B[38;5;241m=\u001B[39m _convert_params(sql, params)\n\u001B[0;32m-> 1560\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1561\u001B[0m columns \u001B[38;5;241m=\u001B[39m result\u001B[38;5;241m.\u001B[39mkeys()\n\u001B[1;32m   1563\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/Data Projects/zoomcamp/pipeline/lib/python3.10/site-packages/pandas/io/sql.py:1405\u001B[0m, in \u001B[0;36mSQLDatabase.execute\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1403\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mexecute\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   1404\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Simple passthrough to SQLAlchemy connectable\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1405\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnectable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecution_options\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Data Projects/zoomcamp/pipeline/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1412\u001B[0m, in \u001B[0;36mConnection.execute\u001B[0;34m(self, statement, parameters, execution_options)\u001B[0m\n\u001B[1;32m   1410\u001B[0m     meth \u001B[38;5;241m=\u001B[39m statement\u001B[38;5;241m.\u001B[39m_execute_on_connection\n\u001B[1;32m   1411\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m-> 1412\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exc\u001B[38;5;241m.\u001B[39mObjectNotExecutableError(statement) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   1413\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1414\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m meth(\n\u001B[1;32m   1415\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1416\u001B[0m         distilled_parameters,\n\u001B[1;32m   1417\u001B[0m         execution_options \u001B[38;5;129;01mor\u001B[39;00m NO_OPTIONS,\n\u001B[1;32m   1418\u001B[0m     )\n",
      "\u001B[0;31mObjectNotExecutableError\u001B[0m: Not an executable object: Text(length=' SELECT * FROM yellow_taxi LIMIT 1000')"
     ]
    }
   ],
   "source": [
    "conn = create_engine('postgresql://root:root@localhost:5432/ny_taxi')\n",
    "pd.read_sql_query(Text(query),con=conn.connect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
